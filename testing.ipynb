{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules \n",
    "from naive_methods.naive_methods import predict_last_value, predict_mean, predict_random_walk\n",
    "from ml_models.ml_models import predict_prophet_model\n",
    "from traditional_models.traditional_models import predict_arima, predict_ets, predict_theta\n",
    "\n",
    "# Pre-processing \n",
    "from data_processing.pre_processing import pre_processing\n",
    "from data_processing.transform import create_df_with_datetimes\n",
    "\n",
    "# Scoring\n",
    "from evaluation_protocol.performance_metrics import mape, smape\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from configparser import ConfigParser\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_train_dataset_df = pd.read_csv('Dataset/Yearly-train.csv')\n",
    "m4_test_dataset_df = pd.read_csv('Dataset/Yearly-test.csv')\n",
    "info_df = pd.read_csv('Dataset/M4-info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(info_df[info_df['category']=='Macro']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_list_macro = []\n",
    "for i in range(80):\n",
    "    timeseries_train_df = create_df_with_datetimes(m4_train_dataset_df, i)\n",
    "    timeseries_test_df = create_df_with_datetimes(m4_test_dataset_df, i)\n",
    "    timeseries_index = m4_test_dataset_df['V1'][i]\n",
    "    target_column_name = timeseries_test_df.columns[1]\n",
    "    real = timeseries_test_df[target_column_name]\n",
    "\n",
    "    predictions, complexity = predict_prophet_model(train=timeseries_train_df, test=timeseries_test_df)\n",
    "    print(predictions)\n",
    "    mape_score = mape(y_true=real,y_pred=predictions)\n",
    "\n",
    "    mape_list_macro.append(mape_score);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3936960664874438\n"
     ]
    }
   ],
   "source": [
    "def avg(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "    \n",
    "print(avg(mape_list_macro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(\"sample_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allowed_file(filename):\n",
    "     # Add the allowed file extensions here\n",
    "    allowed_extensions = set(['csv'])\n",
    "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in allowed_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_upload_path(filename):\n",
    "    check_config_object = ConfigParser()\n",
    "    check_config_object.read(\"test_config.ini\")\n",
    "\n",
    "    #Get the SINGLESCOREINFO section\n",
    "    path_config = check_config_object[\"USERFILE\"]\n",
    "    existing_path = path_config['file_path']\n",
    "\n",
    "    if filename not in existing_path:\n",
    "        path_config['file_path'] = os.path.join('uploads', filename)\n",
    "\n",
    "        #Write changes back to file\n",
    "        with open('test_config.ini', 'w') as conf:\n",
    "            check_config_object.write(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload\n",
    "def upload_file(uploaded_file):\n",
    "\n",
    "    # Check if the file is empty\n",
    "    if uploaded_file == '':\n",
    "        return 'error: No selected file'\n",
    "\n",
    "    # Check if the file has an allowed extension\n",
    "    elif not allowed_file(uploaded_file):\n",
    "        return f'error Invalid file extension, file extenstion: {uploaded_file.rsplit(\".\",1)[1].lower()}'\n",
    "    \n",
    "    else: # Save the uploaded file to a specific location\n",
    "        pre_processing_result = pre_processing(uploaded_file)\n",
    "\n",
    "        if pre_processing_result == True:\n",
    "            update_upload_path(uploaded_file)\n",
    "            return 'message File uploaded successfully'\n",
    "        else: \n",
    "            return f'Pre-processing result: {pre_processing_result}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UPLOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_file('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_file('test.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_file('sample_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_file('wrong_column_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_file('future_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_file('invalid_format.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_user_data(filename):\n",
    "\n",
    "    user_data_df = pd.read_csv(filename)\n",
    "\n",
    "    # 70-30 split with no fancy means\n",
    "    split_index = int(0.7 * len(user_data_df))\n",
    "\n",
    "    train = user_data_df[:split_index]\n",
    "    test = user_data_df[split_index:]\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_user_data('sample_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_last_value = train['target'].tolist()[-1]\n",
    "train_mean = train['target'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "def my_arima(series,forecast_periods):\n",
    "    series = series['target'].astype(float)\n",
    "    forecast_periods = len(forecast_periods)\n",
    "    p = 1\n",
    "    d = 1\n",
    "    q = 2\n",
    "    # train_list = train_df.loc[0][1:].dropna().tolist()\n",
    "    arima_model = ARIMA(series, order=(p,d,q))\n",
    "    arima_results = arima_model.fit()\n",
    "\n",
    "    future_predictions = pd.Series(arima_results.forecast(forecast_periods))\n",
    "\n",
    "    return future_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "def my_prophet(train, test):\n",
    "    train.columns = ['ds', 'y']\n",
    "    test.columns = ['ds', 'y']\n",
    "\n",
    "    model = Prophet(interval_width=0.95)\n",
    "    model.fit(train)\n",
    "    \n",
    "    future_preds = len(test['ds'])\n",
    "\n",
    "    # Make forecasts for as many years as the ones included in the test dataset\n",
    "    future_dates = model.make_future_dataframe(periods=future_preds, freq='YS')\n",
    "\n",
    "    forecast = model.predict(future_dates)\n",
    "\n",
    "    forecast_organized = forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]\n",
    "\n",
    "    predicted = forecast_organized['yhat'][-future_preds:]\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict_last_value(train, test)\n",
    "print(f\"Last value: {train_last_value}\")\n",
    "print(f\"Last value predictions: {preds}\")\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "preds = predict_mean(train, test)\n",
    "print(f\"Mean: {train_mean}\")\n",
    "print(f\"Mean predictions: {preds}\")\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "preds = predict_random_walk(train, test)\n",
    "print(f\"Last value: {train_last_value}\")\n",
    "print(f\"Random walk predictions: {preds}\")\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "preds = predict_arima(train, test)\n",
    "print(f\"Arima predictions: {preds}\")\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "preds = my_arima(train, test)\n",
    "print(f\"My Arima predictions: {preds}\")\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "preds = predict_ets(train, test)\n",
    "print(f\"ETS predictions: {preds}\")\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "preds = predict_theta(train, test)\n",
    "print(f\"Theta predictions: {preds}\")\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "preds = predict_prophet_model(train, test)\n",
    "print(f\"Prophet predictions: {preds}\")\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "preds = my_prophet(train, test)\n",
    "print(f\"My Prophet predictions: {preds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
