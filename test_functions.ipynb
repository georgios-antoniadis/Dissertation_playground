{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from naive_methods.last_value import predict_last_value\n",
    "from naive_methods.only_mean import mean_naive\n",
    "from naive_methods.random_walk import random_walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('Dataset/Yearly-train.csv')\n",
    "test_df = pd.read_csv('Dataset/Yearly-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing on only the very first timeseries\n",
    "first_timeseries_train = train_df.loc[0]\n",
    "first_timeseries_test = test_df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to skip the first column because it is Y1, Y2 etc. \n",
    "mean_naive_predictions = mean_naive(first_timeseries_train[1:], len(first_timeseries_test[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6523.738709677418, 6523.738709677418, 6523.738709677418, 6523.738709677418, 6523.738709677418, 6523.738709677418]\n"
     ]
    }
   ],
   "source": [
    "print(mean_naive_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we need to drop na because the majority of entries are nan! \n",
    "# This could be done more harsely for the dataset we are testing with, however, it is better to generalize for the application\n",
    "last_value_predictions = predict_last_value(first_timeseries_train[1:].dropna(), len(first_timeseries_test[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7261.1, 7261.1, 7261.1, 7261.1, 7261.1, 7261.1]\n"
     ]
    }
   ],
   "source": [
    "print(last_value_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we need to drop na because the last entry might be nan! \n",
    "random_walk_predictions = random_walk(first_timeseries_train[1:].dropna(), len(first_timeseries_test[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7261.1, 7356.02, 7467.070000000001, 7576.570000000001, 7684.340000000001, 7031.740000000001]\n"
     ]
    }
   ],
   "source": [
    "print(random_walk_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Evaluation ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_protocol.grubbs import grubbs_score \n",
    "from evaluation_protocol.mape import mape\n",
    "from evaluation_protocol.smape import smape\n",
    "from evaluation_protocol.shape_similarity import dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No outliers detected.\n",
      "No outliers detected.\n",
      "DTW Distance 2036.3999999999987\n",
      "Optimal Alignment Path: [(0, 0), (1, 0), (2, 1), (2, 2), (3, 3), (4, 4), (5, 5)]\n",
      "Grubbs score for Random Walk is : None\n",
      "SMAPE score for Random Walk is : 4.76081842782954\n",
      "MAPE score for Random Walk is : 4.607188060292931\n",
      "Shape similarity score for Random Walk is : (2036.3999999999987, [(0, 0), (1, 0), (2, 1), (2, 2), (3, 3), (4, 4), (5, 5)])\n",
      "===================================================================================\n",
      "No outliers detected.\n",
      "No outliers detected.\n",
      "DTW Distance 1782.4999999999982\n",
      "Optimal Alignment Path: [(0, 0), (1, 1), (2, 2), (3, 3), (4, 4), (5, 5)]\n",
      "Grubbs score for Last value is : None\n",
      "SMAPE score for Last value is : 3.9799255872447654\n",
      "MAPE score for Last value is : 3.874990013989825\n",
      "Shape similarity score for Last value is : (1782.4999999999982, [(0, 0), (1, 1), (2, 2), (3, 3), (4, 4), (5, 5)])\n",
      "===================================================================================\n",
      "No outliers detected.\n",
      "No outliers detected.\n",
      "DTW Distance 6206.667741935491\n",
      "Optimal Alignment Path: [(0, 0), (1, 1), (2, 2), (3, 3), (4, 4), (5, 5)]\n",
      "Grubbs score for Mean is : None\n",
      "SMAPE score for Mean is : 14.660929581139127\n",
      "MAPE score for Mean is : 13.63643957336176\n",
      "Shape similarity score for Mean is : (6206.667741935491, [(0, 0), (1, 1), (2, 2), (3, 3), (4, 4), (5, 5)])\n",
      "===================================================================================\n"
     ]
    }
   ],
   "source": [
    "predictions = [random_walk_predictions, last_value_predictions, mean_naive_predictions]\n",
    "naive_method_names = ['Random Walk', 'Last value', 'Mean']\n",
    "for i in range(len(naive_method_names)):\n",
    "    predicted = predictions[i]\n",
    "    real = first_timeseries_test[1:]\n",
    "    alpha = 0.05\n",
    "    grubbs_test_score = grubbs_score(predicted, real, alpha)\n",
    "    smape_score = smape(real, predicted)\n",
    "    shape_similarity_score = dtw(predicted, real)\n",
    "    mape_score = mape(real, predicted)\n",
    "\n",
    "    print(f\"Grubbs score for {naive_method_names[i]} is : {grubbs_test_score}\")\n",
    "    print(f\"SMAPE score for {naive_method_names[i]} is : {smape_score}\")\n",
    "    print(f\"MAPE score for {naive_method_names[i]} is : {mape_score}\")\n",
    "    print(f\"Shape similarity score for {naive_method_names[i]} is : {shape_similarity_score}\")\n",
    "    print(\"===================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
